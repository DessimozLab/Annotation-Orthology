{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb7ced0",
   "metadata": {},
   "source": [
    "## Longest isoform NCBI from gff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1edf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "import os\n",
    "import gffutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b29bda58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script takes a while (aprox 30 mins for the 20 sp). For chick, the number of isoforms output is the same as the number of rows in the OMA\n",
    "# splice file.\n",
    "#\n",
    "# TO DO:\n",
    "# - Implement the option of selecting specific folder in which to run the script (e.g. maintain \n",
    "# the option of going through every GCF folder, but also be able to choose which GCF folder to \n",
    "# run the script only)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fda35f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## for only one GCF_0... folder ## ciona in this case (was missing from previous one)\n",
    " \n",
    "gene_to_prot= {}\n",
    "prot_to_gene = {}\n",
    "folder_path = '/directoryto/ncbi_dataset/data/GCFs/GCF_000224145.1'\n",
    "if os.path.isdir(folder_path):\n",
    "    gff = folder_path+'/genomic.gff'\n",
    "    file = folder_path+'/protein.faa'\n",
    "    db = gffutils.create_db(gff, ':memory:', merge_strategy=\"create_unique\", keep_order=True)\n",
    "        # Loop through all genes\n",
    "    for t in db.features_of_type('gene', order_by='start'):\n",
    "        gene = t.id\n",
    "        gene_list = []\n",
    "        ordered_child = list(db.children(t, featuretype='CDS', order_by='start'))\n",
    "            \n",
    "        # Loop through all children of genes\n",
    "        for child in ordered_child:\n",
    "            type_attribute = ['protein_id', 'Name']\n",
    "                \n",
    "            # Loop through all proteins of children??\n",
    "            for att_type in type_attribute:\n",
    "                protein = child.attributes.get(att_type, [None])[0]\n",
    "                if protein:\n",
    "                    break\n",
    "                        \n",
    "            if not protein:\n",
    "                print('warning')\n",
    "                print(child)\n",
    "                continue\n",
    "                \n",
    "            corr_gene = prot_to_gene.get(protein, None)\n",
    "            #if there was already a gene for this protein, replace it for the previous one\n",
    "            if corr_gene and corr_gene!=gene:\n",
    "                gene = corr_gene\n",
    "                # now make sure the other proteins in the same gene (gene_list-a list of the proteins inside this gene)\n",
    "                # have the same gene associated\n",
    "                for other_prot in gene_list: \n",
    "                    prot_to_gene[other_prot] = gene\n",
    "                gene_list = gene_to_prot[gene]+gene_list #Add this protein and the corresponding previous ones to the list of prots in this gene\n",
    "            else:\n",
    "                prot_to_gene[protein] = gene\n",
    "            if protein not in gene_list:\n",
    "                gene_list.append(protein)\n",
    "        if len(gene_list)!=0:\n",
    "            gene_to_prot[gene] = gene_list\n",
    "    #print(prot_to_gene)    \n",
    "    \n",
    "    # Now we have the gene_to_prot and prot_to_gene information for this current folder (species), let's proceed to select the\n",
    "    # longest one using the .faa file.\n",
    "seen = set()\n",
    "mydict = {}\n",
    "for seq_record in SeqIO.parse(file, 'fasta'):\n",
    "    sequence_len = len(seq_record.seq)\n",
    "    gene = prot_to_gene[seq_record.id]\n",
    "    \n",
    "    if gene not in seen:\n",
    "        mydict[gene]= {'length': sequence_len, 'ID': seq_record.id}\n",
    "        seen.add(gene)\n",
    "    elif mydict[gene]['length'] < sequence_len:\n",
    "        mydict.pop(gene)\n",
    "        mydict[gene]= {'length': sequence_len, 'ID': seq_record.id}\n",
    "            \n",
    "#Now that we have a dictionary with each gene and its longest isoform, let's create the output fasta with them\n",
    "accession_numbers = []\n",
    "sequences=[]\n",
    "for key in mydict:\n",
    "    accession_numbers.append(mydict[key]['ID'])\n",
    "        \n",
    "for seq_record in SeqIO.parse(file, 'fasta'):\n",
    "    if seq_record.id in accession_numbers:\n",
    "        sequences.append(seq_record)\n",
    "            \n",
    "with open(folder_path+'/longestiso.faa', 'w') as outfile:\n",
    "    SeqIO.write(sequences, outfile, \"fasta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "474f7d08",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m seen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[1;32m     57\u001b[0m mydict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 58\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m seq_record \u001b[38;5;129;01min\u001b[39;00m SeqIO\u001b[38;5;241m.\u001b[39mparse(\u001b[43mfile\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfasta\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     59\u001b[0m     sequence_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(seq_record\u001b[38;5;241m.\u001b[39mseq)\n\u001b[1;32m     60\u001b[0m     gene \u001b[38;5;241m=\u001b[39m prot_to_gene[seq_record\u001b[38;5;241m.\u001b[39mid]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file' is not defined"
     ]
    }
   ],
   "source": [
    "##### SPECIFIC FOR NCBI. All folders in original_dir need to be genomes folders with genomic.gff (& protein.faa) \n",
    "##### inside                                                                                            \n",
    "\n",
    "\n",
    "original_dir = '/directoryto/ncbi_dataset/data/GCFs/'\n",
    "\n",
    "for folder in os.listdir(original_dir):\n",
    "    gene_to_prot= {}\n",
    "    prot_to_gene = {}\n",
    "    folder_path = original_dir + folder\n",
    "    if os.path.isdir(folder_path):\n",
    "        gff = folder_path+'/genomic.gff'\n",
    "        file = folder_path+'/protein.faa'\n",
    "        db = gffutils.create_db(gff, ':memory:', merge_strategy=\"create_unique\", keep_order=True)\n",
    "        # Loop through all genes\n",
    "        for t in db.features_of_type('gene', order_by='start'):\n",
    "            gene = t.id\n",
    "            gene_list = []\n",
    "            ordered_child = list(db.children(t, featuretype='CDS', order_by='start'))\n",
    "            \n",
    "            # Loop through all children of genes\n",
    "            for child in ordered_child:\n",
    "                type_attribute = ['protein_id', 'Name']\n",
    "                \n",
    "                # Loop through all proteins of children??\n",
    "                for att_type in type_attribute:\n",
    "                    protein = child.attributes.get(att_type, [None])[0]\n",
    "                    if protein:\n",
    "                        break\n",
    "                        \n",
    "                if not protein:\n",
    "                    print('warning')\n",
    "                    print(child)\n",
    "                    continue\n",
    "                \n",
    "                corr_gene = prot_to_gene.get(protein, None)\n",
    "                #if there was already a gene for this protein, replace it for the previous one\n",
    "                if corr_gene and corr_gene!=gene:\n",
    "                    gene = corr_gene\n",
    "                    # now make sure the other proteins in the same gene (gene_list-a list of the proteins inside this gene)\n",
    "                    # have the same gene associated\n",
    "                    for other_prot in gene_list: \n",
    "                        prot_to_gene[other_prot] = gene\n",
    "                    gene_list = gene_to_prot[gene]+gene_list #Add this protein and the corresponding previous ones to the list of prots in this gene\n",
    "                else:\n",
    "                    prot_to_gene[protein] = gene\n",
    "                if protein not in gene_list:\n",
    "                    gene_list.append(protein)\n",
    "            if len(gene_list)!=0:\n",
    "                gene_to_prot[gene] = gene_list\n",
    "    #print(prot_to_gene)    \n",
    "    \n",
    "    # Now we have the gene_to_prot and prot_to_gene information for this current folder (species),\n",
    "    # let's proceed to select the longest one using the .faa file.\n",
    "    seen = set()\n",
    "    mydict = {}\n",
    "    for seq_record in SeqIO.parse(file, 'fasta'):\n",
    "        sequence_len = len(seq_record.seq)\n",
    "        gene = prot_to_gene[seq_record.id]\n",
    "    \n",
    "        if gene not in seen:\n",
    "            mydict[gene]= {'length': sequence_len, 'ID': seq_record.id}\n",
    "            seen.add(gene)\n",
    "        elif mydict[gene]['length'] < sequence_len:\n",
    "            mydict.pop(gene)\n",
    "            mydict[gene]= {'length': sequence_len, 'ID': seq_record.id}\n",
    "            \n",
    "    #Now that we have a dictionary with each gene and its longest isoform, \n",
    "    # let's create the output fasta with them\n",
    "    accession_numbers = []\n",
    "    sequences=[]\n",
    "    for key in mydict:\n",
    "        accession_numbers.append(mydict[key]['ID'])\n",
    "        \n",
    "    for seq_record in SeqIO.parse(file, 'fasta'):\n",
    "        if seq_record.id in accession_numbers:\n",
    "            sequences.append(seq_record)\n",
    "            \n",
    "    with open(folder_path+'/longestiso.faa', 'w') as outfile:\n",
    "        SeqIO.write(sequences, outfile, \"fasta\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e38dd3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "corr=pd.read_csv('/directoryto/ncbi_dataset/data/SpeciesInfo.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4abce509",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr.rename(columns={\"Correct NCBI refseq\": \"Correct_NCBI_refseq\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a578a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NCBIrs= list(corr[\"Correct_NCBI_refseq\"])\n",
    "NCBIrs = [item for item in NCBIrs if not(pd.isnull(item)) == True]\n",
    "spcode=list(corr[\"Code\"])\n",
    "spcode=[item for item in spcode if not(pd.isnull(item)) == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d470a613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from os.path import exists\n",
    "\n",
    "for (ref, code) in zip(NCBIrs,spcode):\n",
    "    original = r'/directoryto/ncbi_dataset/data/GCFs/' + ref +'/longestiso.faa'\n",
    "    target = r'/directoryto/orthofinder_runs/OrthoFinder/topNCBI20/longestisos/'+ code + '.fa'\n",
    "    isExisting = os.path.exists(original)\n",
    "    if not isExisting:\n",
    "        print('This file does not exist')\n",
    "        print(original)\n",
    "        continue\n",
    "    shutil.copyfile(original, target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
